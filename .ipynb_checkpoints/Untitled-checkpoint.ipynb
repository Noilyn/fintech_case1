{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T15:18:35.633246Z",
     "start_time": "2020-03-27T15:18:34.784024Z"
    }
   },
   "outputs": [],
   "source": [
    "from dateutil.relativedelta import relativedelta\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T15:19:22.039790Z",
     "start_time": "2020-03-27T15:19:19.838667Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv('traindata.csv')\n",
    "df['date'] = pd.to_datetime(df['date'])\n",
    "df = df[df['date']!=pd.datetime(2015,11,11)]\n",
    "df = df[df['date']!=pd.datetime(2015,12,12)]\n",
    "df['store_code'] = df['store_code'].astype('str')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-27T15:32:03.339986Z",
     "start_time": "2020-03-27T15:32:03.319476Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "date                 object\n",
       "item_id               int64\n",
       "store_code           object\n",
       "cate_id               int64\n",
       "cate_level_id         int64\n",
       "brand_id              int64\n",
       "supplier_id           int64\n",
       "pv_ipv                int64\n",
       "pv_uv                 int64\n",
       "cart_ipv              int64\n",
       "cart_uv               int64\n",
       "collect_uv            int64\n",
       "num_gmv               int64\n",
       "amt_gmv             float64\n",
       "qty_gmv               int64\n",
       "unum_gmv              int64\n",
       "amt_alipay          float64\n",
       "num_alipay            int64\n",
       "qty_alipay            int64\n",
       "unum_alipay           int64\n",
       "ztc_pv_ipv            int64\n",
       "tbk_pv_ipv            int64\n",
       "ss_pv_ipv             int64\n",
       "jhs_pv_ipv            int64\n",
       "ztc_pv_uv             int64\n",
       "tbk_pv_uv             int64\n",
       "ss_pv_uv              int64\n",
       "jhs_pv_uv             int64\n",
       "num_alipay_njhs       int64\n",
       "amt_alipay_njhs     float64\n",
       "qty_alipay_njhs       int64\n",
       "unum_alipay_njhs      int64\n",
       "dtype: object"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T03:57:41.398401Z",
     "start_time": "2020-03-28T03:57:41.372672Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def sub_window(df_sub, start_date, time_delta):\n",
    "    end_date = start_date + relativedelta(days=time_delta)\n",
    "    df_tmp = df_sub[df_sub['date']<=end_date]\n",
    "    df_tmp = df_tmp[df_tmp['date']>=start_date]\n",
    "    df_tmp_amount = df_tmp[['pv_ipv', 'pv_uv', 'cart_ipv', 'cart_uv', 'collect_uv', 'num_gmv', 'amt_gmv', \n",
    "                            'qty_gmv', 'unum_gmv', 'amt_alipay', 'num_alipay', 'qty_alipay', 'unum_alipay',\n",
    "                            'ztc_pv_ipv', 'tbk_pv_ipv', 'ss_pv_ipv', 'jhs_pv_ipv', 'ztc_pv_uv', 'tbk_pv_uv',\n",
    "                            'ss_pv_uv', 'jhs_pv_uv', 'num_alipay_njhs', 'amt_alipay_njhs', 'qty_alipay_njhs',\n",
    "                            'unum_alipay_njhs', 'item_id']]\n",
    "    grouped = df_tmp_amount.groupby(['item_id'])\n",
    "    sum_ = grouped.sum()\n",
    "    sum_.columns = map(lambda x: str(x) + '_%s' % str(time_delta) + '_%s' % 'sum_', sum_.columns)\n",
    "    mean_ = grouped.mean()\n",
    "    mean_.columns = map(lambda x: str(x) + '_%s' % str(time_delta) + '_%s' % 'mean_', mean_.columns)\n",
    "    sum_mean_ = pd.merge(sum_, mean_, on='item_id')\n",
    "    return sum_mean_\n",
    "\n",
    "def generate_window(df_sub, start_date):\n",
    "    window_sub = [1, 2, 3, 5, 7, 9, 11, 14]\n",
    "    sum_mean = sub_window(df_sub, start_date, window_sub[0])\n",
    "    for i in range(1, 8):\n",
    "        tmp = sub_window(df_sub, start_date, window_sub[i])\n",
    "        sum_mean = pd.merge(sum_mean, tmp, on='item_id')\n",
    "    end_date = start_date + relativedelta(days=14)\n",
    "    \n",
    "    tmp = df_sub[['item_id', 'qty_alipay_njhs']]\n",
    "    grouped = tmp.groupby(['item_id'])\n",
    "    sum_mean = pd.merge(sum_mean, pd.merge(pd.merge(grouped.max(), grouped.min(), on='item_id'), grouped.std(), on='item_id'), on='item_id')\n",
    "    tmp_ = sum_mean.columns.values\n",
    "    sum_mean.rename(columns={tmp_[-3]: 'item_njhs_max', tmp_[-2]: 'item_njhs_min', tmp_[-1]: 'item_njhs_std'}, inplace=True)\n",
    "    \n",
    "    tmp = df_sub[['item_id', 'cate_id', 'qty_alipay_njhs']]\n",
    "    grouped = tmp.groupby(['item_id', 'cate_id'])\n",
    "    sum_mean = pd.merge(sum_mean, pd.merge(pd.merge(grouped.max(), grouped.min(), on=['item_id', 'cate_id']), grouped.std(), on=['item_id', 'cate_id']), on='item_id')\n",
    "    tmp_ = sum_mean.columns.values\n",
    "    sum_mean.rename(columns={tmp_[-3]: 'cate_njhs_max', tmp_[-2]: 'cate_njhs_min', tmp_[-1]: 'cate_njhs_std'}, inplace=True)\n",
    "    \n",
    "    tmp = df_sub[['item_id', 'cate_level_id', 'qty_alipay_njhs']]\n",
    "    grouped = tmp.groupby(['item_id', 'cate_level_id'])\n",
    "    sum_mean = pd.merge(sum_mean, pd.merge(pd.merge(grouped.max(), grouped.min(), on=['item_id', 'cate_level_id']), grouped.std(), on=['item_id', 'cate_level_id']), on='item_id')\n",
    "    tmp_ = sum_mean.columns.values\n",
    "    sum_mean.rename(columns={tmp_[-3]: 'cate_level_njhs_max', tmp_[-2]: 'cate_level_njhs_min', tmp_[-1]: 'cate_level_njhs_std'}, inplace=True)\n",
    "    \n",
    "    tmp = df_sub[['item_id', 'brand_id', 'qty_alipay_njhs']]\n",
    "    grouped = tmp.groupby(['item_id', 'brand_id'])\n",
    "    sum_mean = pd.merge(sum_mean, pd.merge(pd.merge(grouped.max(), grouped.min(), on=['item_id', 'brand_id']), grouped.std(), on=['item_id', 'brand_id']), on='item_id')\n",
    "    tmp_ = sum_mean.columns.values\n",
    "    sum_mean.rename(columns={tmp_[-3]: 'brand_njhs_max', tmp_[-2]: 'brand_njhs_min', tmp_[-1]: 'brand_njhs_std'}, inplace=True)\n",
    "    \n",
    "    tmp = df_sub[['item_id', 'supplier_id', 'qty_alipay_njhs']]\n",
    "    grouped = tmp.groupby(['item_id', 'supplier_id'])\n",
    "    sum_mean = pd.merge(sum_mean, pd.merge(pd.merge(grouped.max(), grouped.min(), on=['item_id', 'supplier_id']), grouped.std(), on=['item_id', 'supplier_id']), on='item_id')\n",
    "    tmp_ = sum_mean.columns.values\n",
    "    sum_mean.rename(columns={tmp_[-3]: 'supplier_njhs_max', tmp_[-2]: 'supplier_njhs_min', tmp_[-1]: 'supplier_njhs_std'}, inplace=True)\n",
    "    return sum_mean\n",
    "\n",
    "def store_code_train(df_sub, start_date):\n",
    "    window_sub = generate_window(df_1, start_date)\n",
    "    for i in range(interval.days // 14):\n",
    "        start_date += relativedelta(days=14)\n",
    "        window_sub = pd.concat([window_sub, generate_window(df_1, start_date)])\n",
    "    return window_sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-03-28T03:56:40.155006Z",
     "start_time": "2020-03-28T03:56:40.143061Z"
    }
   },
   "outputs": [],
   "source": [
    "df_1 = df[df['store_code']=='1']\n",
    "df_2 = df[df['store_code']=='2']\n",
    "df_3 = df[df['store_code']=='3']\n",
    "df_4 = df[df['store_code']=='4']\n",
    "df_5 = df[df['store_code']=='5']\n",
    "df_all = df[df['store_code']=='all']\n",
    "interval = df['date'].max() - df['date'].min()\n",
    "start_date = df['date'].min()\n",
    "store_code_1 = store_code_train(df_1, start_date)\n",
    "joblib.dump(store_code_1, os.getcwd()+'/datasets/store_code_1.pkl')\n",
    "store_code_2 = store_code_train(df_2, start_date)\n",
    "joblib.dump(store_code_2, os.getcwd()+'/datasets/store_code_2.pkl')\n",
    "store_code_3 = store_code_train(df_3, start_date)\n",
    "joblib.dump(store_code_3, os.getcwd()+'/datasets/store_code_3.pkl')\n",
    "store_code_4 = store_code_train(df_4, start_date)\n",
    "joblib.dump(store_code_4, os.getcwd()+'/datasets/store_code_4.pkl')\n",
    "store_code_5 = store_code_train(df_5, start_date)\n",
    "joblib.dump(store_code_5, os.getcwd()+'/datasets/store_code_5.pkl')\n",
    "store_code_all = store_code_train(df_all, start_date)\n",
    "joblib.dump(store_code_all, os.getcwd()+'/datasets/store_code_all.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
